{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from numpy import isnan\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/electricity.zip'):\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip'\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "\n",
    "    with open(\"data/electricity.zip\",\"wb\") as handle:\n",
    "        for data in tqdm(response.iter_content()):\n",
    "            handle.write(data)\n",
    "\n",
    "    with zipfile.ZipFile(\"data/electricity.zip\",'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")\n",
    "\n",
    "    os.rename('data/household_power_consumption.txt','data/household_power_consumption.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 60\n",
    "feature_dim = 24*60//resolution\n",
    "df_raw = pd.read_csv('data/household_power_consumption.csv', sep=';', index_col=False, low_memory=False, na_values='?')\n",
    "df_raw = df_raw.iloc[21996::resolution,:3]\n",
    "df_raw['datetime'] = pd.to_datetime(df_raw['Date']+' '+df_raw['Time'], infer_datetime_format=True, dayfirst=True)\n",
    "df_raw = df_raw.drop(['Date','Time'],axis=1)\n",
    "df_raw = df_raw.set_index(['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:1396\n"
     ]
    }
   ],
   "source": [
    "g = df_raw.groupby(df_raw.index.floor('d'))\n",
    "\n",
    "daily_data = []\n",
    "my_day, final_day = df_raw.index[0].date(), df_raw.index[-1].date()\n",
    "\n",
    "while my_day < final_day:\n",
    "    try:\n",
    "        day_data = g.get_group(my_day).T.values.tolist()[0]\n",
    "    except:\n",
    "        print(\"Date \"+str(my_day)+\" is missing.\")\n",
    "        my_day += timedelta(days=1)\n",
    "    else:\n",
    "        if (not isnan(day_data).any()) and day_data.__len__() == feature_dim:\n",
    "            row_data = [my_day.month, my_day.weekday()] + day_data\n",
    "            daily_data.append(row_data)\n",
    "        my_day += timedelta(days=1)\n",
    "\n",
    "print('Dataset Size:'+str(daily_data.__len__()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['month', 'weekday']\n",
    "my_day = pd.Timestamp('2012-01-01')\n",
    "for _ in range(feature_dim):\n",
    "    column_names.append(my_day.strftime('%H:%M'))\n",
    "    my_day+=timedelta(minutes=resolution)\n",
    "\n",
    "# %%\n",
    "df_daily = pd.DataFrame(daily_data,columns=column_names)\n",
    "df_daily.to_csv('data/daily_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ratio = 0.8\n",
    "df_train, df_test = train_test_split(df_daily, train_size=train_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityData(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        data = torch.tensor(df.values).float()\n",
    "        self.inputs = data[:,2:]\n",
    "        self.mean = self.inputs.mean(dim=0)\n",
    "        self.std = self.inputs.std(dim=0)\n",
    "        self.inputs = (self.inputs-self.mean)/self.std\n",
    "\n",
    "        self.conditions = self.circlize(data[:,[[0],[1]]])\n",
    "\n",
    "    def circlize(self,condition):\n",
    "        max_conds = torch.max(condition,dim=0,keepdim=False)[0]\n",
    "        min_conds = torch.min(condition,dim=0,keepdim=False)[0]\n",
    "        return torch.cat((torch.cos((condition-min_conds)/(max_conds-min_conds+1)*2*torch.pi),torch.sin((condition-min_conds)/(max_conds-min_conds+1)*2*torch.pi)),dim=2).reshape(condition.shape[0],-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        return self.inputs[idx], self.conditions[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NEURONS = 50\n",
    "ACTIVATION = torch.nn.CELU(inplace=True)\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,input_dim,latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(input_dim, NUM_NEURONS)\n",
    "        self.fc2 = torch.nn.Linear(NUM_NEURONS, NUM_NEURONS)\n",
    "        self.fc_mean = torch.nn.Linear(NUM_NEURONS, latent_dim)\n",
    "        self.fc_sigmatilde = torch.nn.Linear(NUM_NEURONS, latent_dim)\n",
    "\n",
    "        # setup the non-linearity\n",
    "        self.act = ACTIVATION\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x.view(-1, self.input_dim)\n",
    "        h = self.act(self.fc1(h))\n",
    "        h = self.act(self.fc2(h))\n",
    "        z_mean = self.fc_mean(h)\n",
    "        z_sigmatilde = self.fc_sigmatilde(h)\n",
    "        return z_mean, z_sigmatilde\n",
    "\n",
    "    def _num_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,output_dim,latent_dim,learn_sigma=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_dim = output_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learn_sigma = learn_sigma\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(latent_dim, NUM_NEURONS)\n",
    "        self.fc2 = torch.nn.Linear(NUM_NEURONS, NUM_NEURONS)\n",
    "        self.fc_mean = torch.nn.Linear(NUM_NEURONS, output_dim)\n",
    "        if learn_sigma: self.fc_sigmatilde = torch.nn.Linear(NUM_NEURONS, output_dim)\n",
    "\n",
    "        # setup the non-linearity\n",
    "        self.act = ACTIVATION\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = z.view(-1, self.latent_dim)\n",
    "        h = self.act(self.fc1(h))\n",
    "        h = self.act(self.fc2(h))\n",
    "        x_mean = self.fc_mean(h)\n",
    "        if self.learn_sigma:\n",
    "            x_sigmatilde = self.fc_sigmatilde(h)\n",
    "        else:\n",
    "            x_sigmatilde = 0.0*x_mean\n",
    "        return x_mean, x_sigmatilde\n",
    "\n",
    "    def _num_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self,input_dim=24, cond_dim=4, latent_dim=10, learn_sigma=True):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.input_dim, self.cond_dim, self.latent_dim = input_dim, cond_dim, latent_dim\n",
    "\n",
    "        self.encoder = Encoder(self.input_dim+self.cond_dim, self.latent_dim)\n",
    "        self.decoder = Decoder(self.input_dim, self.latent_dim+self.cond_dim, learn_sigma)\n",
    "        \n",
    "        self.num_parameters = self.encoder._num_parameters()+self.decoder._num_parameters()\n",
    "    \n",
    "    def forward(self,inputs,conditions):\n",
    "        z_mean, z_sigmatilde = self.encoder(torch.cat((inputs,conditions),dim=1))\n",
    "        z = self.sample(z_mean, z_sigmatilde)\n",
    "        x_mean, x_sigmatilde = self.decoder(torch.cat((z,conditions),dim=1))\n",
    "        return {\"mean\": x_mean, \"sigmatilde\": x_sigmatilde}, {\"mean\": z_mean, \"sigmatilde\": z_sigmatilde, \"sample\": z} \n",
    "\n",
    "    def sample(self,mean,sigmatilde):\n",
    "        eps = torch.randn(mean.shape)\n",
    "        return mean + eps*self.to_sigma(sigmatilde)\n",
    "\n",
    "    def reconstruction_loglikelihood(self, input, mean, sigmatilde):\n",
    "        sigma = self.to_sigma(sigmatilde)\n",
    "        return (-.5*(torch.tensor(2)*torch.pi).log()-sigma.log()-.5*((input-mean)/sigma).pow(2)).sum(dim=1)\n",
    "\n",
    "    def kl_divergence(self, mean_posterior, sigmatilde_posterior, mean_prior=None, sigmatilde_prior=None):\n",
    "        if mean_prior is None: mean_prior = mean_posterior*0.0\n",
    "        if sigmatilde_prior is None: sigmatilde_prior =  self.from_sigma(sigmatilde_posterior*0.0 + 1.0)\n",
    "\n",
    "        sigma_posterior = self.to_sigma(sigmatilde_posterior)\n",
    "        sigma_prior = self.to_sigma(sigmatilde_prior)\n",
    "\n",
    "        return .5*((sigma_posterior/sigma_prior).pow(2) + ((mean_posterior-mean_prior)/sigma_prior).pow(2) -1 + 2*(sigma_prior.log()-sigma_posterior.log())).sum(dim=1)\n",
    "    \n",
    "    def loss(self, input, x_mean, x_sigmatilde, z_mean, z_sigmatilde, beta=1):\n",
    "        rll = self.reconstruction_loglikelihood(input,x_mean,x_sigmatilde).mean(dim=0)\n",
    "        kl = self.kl_divergence(z_mean,z_sigmatilde).mean(dim=0)\n",
    "        return {\"loss\":-(rll-beta*kl), \"elbo\": rll-kl, \"rll\": rll, \"kl\": kl}\n",
    "\n",
    "    def to_sigma(self,sigmatilde):\n",
    "        return torch.log2(1+torch.pow(torch.tensor(2),sigmatilde))\n",
    "\n",
    "    def from_sigma(self,sigma):\n",
    "        return torch.log2(torch.pow(torch.tensor(2),sigma)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 1000\n",
    "beta = 1\n",
    "learning_rate = 1e-3\n",
    "latent_dim = 2\n",
    "verbose_freq = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = ElectricityData(df_train)\n",
    "train_loader = torch.utils.data.DataLoader(dset,batch_size=32,shuffle=True,drop_last=True)\n",
    "model = VAE(input_dim=feature_dim, cond_dim=4, latent_dim=latent_dim)\n",
    "\n",
    "pbar = tqdm(total=(dset.__len__()//batch_size+1) * epochs)\n",
    "\n",
    "optim = torch.optim.Adam([{'params':model.encoder.parameters()},\n",
    "                        {'params':model.decoder.parameters()}],lr=learning_rate)\n",
    "\n",
    "epx = 0\n",
    "itx = 0\n",
    "for _ in range(epochs):\n",
    "    epx += 1\n",
    "    for inputs, conditions in train_loader:\n",
    "        itx += 1\n",
    "        pbar.update(1)\n",
    "        x_dict, z_dict = model.forward(inputs, conditions)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss = model.loss(inputs,x_dict[\"mean\"],x_dict[\"sigmatilde\"],z_dict[\"mean\"],z_dict[\"sigmatilde\"])\n",
    "        loss[\"loss\"].backward()\n",
    "        optim.step()\n",
    "\n",
    "        if itx%verbose_freq==0: \n",
    "            pbar.write(f\"Iteration: {itx} -- RLL={loss['rll'].item():.4f} / KL={loss['kl'].item():.4f}\")\n",
    "            pbar.write(f\"Min_sigmatilde: {x_dict['sigmatilde'].min().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #End of Epoch\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #region Train Viz\n",
    "        #TODO: Shuffle=False is needed rn. Find a way to keep same training sample\n",
    "        denorm_inputs = denormalize(inputs[0],stats['mean'],stats['vh'],stats['std'])\n",
    "        denorm_x = denormalize(x_dict['mean'][0],stats['mean'],stats['vh'],stats['std'])\n",
    "        denorm_sigma = denormalize_sigma(x_dict['sigmatilde'][0],stats['vh'],stats['std'])\n",
    "\n",
    "        #region Viz block\n",
    "        fig, ax = viz.compare_with_bounds(denorm_inputs,denorm_x,denorm_sigma,fig_no=1)\n",
    "        ax.set_title(f\"Training Sample (Epoch: {epx:03d})\")\n",
    "        ax.set_ylabel(\"Consumption [kWh]\")\n",
    "        ax.set_xticks(list(range(0,48,6)),get_timeslots(30*6))\n",
    "        if self.savefig: \n",
    "            savedir = self.log_dir+\"/train_imgs\"\n",
    "            if not os.path.isdir(savedir):\n",
    "                os.makedirs(savedir)\n",
    "            with open(savedir+\"/makegif.sh\",'w') as f:\n",
    "                f.write(\"convert -delay 10 -loop 0 *.png myimage.gif\")\n",
    "            plt.savefig(savedir+f\"/{epx:03d}\")\n",
    "        #endregion\n",
    "        #endregion\n",
    "\n",
    "        #region Validation\n",
    "        x_dict, z_dict = self.forward(**valset)\n",
    "        inputs = valset[\"inputs\"]\n",
    "\n",
    "        denorm_inputs = denormalize(inputs,stats['mean'],stats['vh'],stats['std'])\n",
    "        denorm_x = denormalize(x_dict['mean'],stats['mean'],stats['vh'],stats['std'])\n",
    "        denorm_sigma = denormalize_sigma(x_dict['sigmatilde'],stats['vh'],stats['std'])\n",
    "\n",
    "        rmse = (denorm_inputs-denorm_x).pow(2).mean()\n",
    "        loss = self.loss(inputs,x_dict[\"mean\"],x_dict[\"sigmatilde\"],z_dict[\"mean\"],z_dict[\"sigmatilde\"]) \n",
    "        self.pbar.write(f\"Validation -- RLL={loss['rll'].item():.4f} / KL={loss['kl'].item():.4f}\")\n",
    "        self.pbar.write(f\"Validation -- RMSE={rmse.item():.4f}\")\n",
    "\n",
    "        #region Viz block\n",
    "        idx = 0\n",
    "        fig, ax = viz.compare_with_bounds(denorm_inputs[idx],denorm_x[idx],denorm_sigma[idx],fig_no=2)\n",
    "        ax.set_title(f\"Validation Sample (Epoch: {epx:03d})\")\n",
    "        ax.set_ylabel(\"Consumption [kWh]\")\n",
    "        ax.set_xticks(list(range(0,48,6)),get_timeslots(30*6))\n",
    "        if self.savefig: \n",
    "            savedir = self.log_dir+\"/val_imgs\"\n",
    "            if not os.path.isdir(savedir):\n",
    "                os.makedirs(savedir)\n",
    "            with open(savedir+\"/makegif.sh\",'w') as f:\n",
    "                f.write(\"convert -delay 10 -loop 0 *.png myimage.gif\")\n",
    "            plt.savefig(savedir+f\"/{epx:03d}\")\n",
    "        #endregion\n",
    "\n",
    "        plt.show(block=False)\n",
    "        plt.pause(0.1)\n",
    "        #endregion\n",
    "\n",
    "        #region Tensorboard Visualization\n",
    "        if self.viz:\n",
    "            if self.viz: \n",
    "                self.writer.add_scalars('Loss/RLL', {'val':loss['rll']}, itx)\n",
    "                self.writer.add_scalars('Loss/KL', {'val':loss['kl']}, itx)\n",
    "        #endregion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8056385a05999709b5cae6043df902d7bb596f3f2a3ddb52cf32b89e8788e927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
